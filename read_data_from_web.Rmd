---
title: "Read Data From Web"
output: github_document
---

```{r eval = FALSE}
#一般画图的操作：预先设定好自己喜欢的theme和color
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal()+theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis")

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

```{r}
library(rvest)
library(httr)
library(tidyverse)
```

```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

drug_use_html = read_html(url)
```

Get the pieces I actually need
```{r}
marj_use_df = drug_use_html |>
  html_table() |>
  dplyr::first() |>
  dplyr::slice(-1)
```

exercise: use the living table of New York website
```{r}
cost_of_living = read_html("https://www.bestplaces.net/cost_of_living/city/new_york/new_york") |>
  html_table(header = TRUE) |>
  dplyr::first()
## header = TRUE的意思是让表格的第一行成为标题（如果不用这个代码的话，R会自动补充X1 X2 X3 X4成为标题，在这个例子中  
```

**用nth（x,n,order_by = NULL..)可以取第n个表格








